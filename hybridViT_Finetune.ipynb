{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FB5-_c-NYVlg",
        "outputId": "206a8323-2558-4e5a-d9fb-4cf0f2ee4a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist) (11.1.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.21.0+cu124)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist) (3.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install medmnist\n",
        "!pip install wandb\n",
        "!pip install transformers\n",
        "!pip install -q --upgrade transformers\n",
        "!pip install pillow\n",
        "!pip install evaluate\n",
        "!pip install torch\n",
        "!pip install optuna\n",
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNXVclQqDhqE",
        "outputId": "f6efe4e9-30f4-4ed6-9520-18a1bc711f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsA-tBDZcHaC",
        "outputId": "15515220-4eb9-4d11-8f9b-0ccced4350fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmlabrie0208\u001b[0m (\u001b[33mmlabrie0208-polytechnique-montr-al\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHz-OcFZccGc",
        "outputId": "4f4c34c1-31d7-4b12-c253-8ce57ac6fa1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "4.51.3\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "print(torch.cuda.is_available())\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "from transformers import (\n",
        "    ViTHybridImageProcessor,\n",
        "    ViTHybridForImageClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "import transformers\n",
        "print(transformers.__version__)\n",
        "from medmnist import INFO\n",
        "from medmnist.dataset import MedMNIST\n",
        "import medmnist.dataset as mds\n",
        "from PIL import Image\n",
        "import evaluate\n",
        "from medmnist import PathMNIST, DermaMNIST, BloodMNIST, RetinaMNIST\n",
        "sys.path.append('/content/drive/MyDrive/Project_Deep_Learning')\n",
        "from data_augmentation import *\n",
        "from evaluate import load\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv-UAd7sd3kY"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-S8czClcscE",
        "outputId": "9b03a849-b9c5-4ebf-bbbc-ac018605b92a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading datasets...\n",
            "Number of unique labels: 29\n"
          ]
        }
      ],
      "source": [
        "# Download and load datasets\n",
        "print(\"Downloading datasets...\")\n",
        "path_dataset = PathMNIST(split=\"train\", download=True, as_rgb=True)\n",
        "derma_dataset = DermaMNIST(split=\"train\", download=True, as_rgb=True)\n",
        "blood_dataset = BloodMNIST(split=\"train\", download=True, as_rgb=True)\n",
        "retina_dataset = RetinaMNIST(split=\"train\", download=True, as_rgb=True)\n",
        "\n",
        "val_path_dataset = PathMNIST(split=\"val\", download=True)\n",
        "val_derma_dataset = DermaMNIST(split=\"val\", download=True)\n",
        "val_blood_dataset = BloodMNIST(split=\"val\", download=True)\n",
        "val_retina_dataset = RetinaMNIST(split=\"val\", download=True)\n",
        "\n",
        "test_path_dataset = PathMNIST(split=\"test\", download=True)\n",
        "test_derma_dataset = DermaMNIST(split=\"test\", download=True)\n",
        "test_blood_dataset = BloodMNIST(split=\"test\", download=True)\n",
        "test_retina_dataset = RetinaMNIST(split=\"test\", download=True)\n",
        "\n",
        "# Create a unified label set across the datasets\n",
        "pathmnist_info = INFO[\"pathmnist\"]\n",
        "dermamnist_info = INFO[\"dermamnist\"]\n",
        "bloodmnist_info = INFO[\"bloodmnist\"]\n",
        "retinamnist_info = INFO[\"retinamnist\"]\n",
        "\n",
        "labels = set(pathmnist_info[\"label\"].values())\n",
        "labels.update(dermamnist_info[\"label\"].values())\n",
        "labels.update(bloodmnist_info[\"label\"].values())\n",
        "labels.update(retinamnist_info[\"label\"].values())\n",
        "labels = sorted(list(labels))\n",
        "num_labels = len(labels)\n",
        "print(\"Number of unique labels:\", num_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xJEDKo6XgY2T"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "class CustomMNIST(Dataset):\n",
        "  def __init__(self, dataset, *args, **kwargs):\n",
        "\n",
        "    super(CustomMNIST, self).__init__()\n",
        "\n",
        "    self.data_transform = transforms.Compose([\n",
        "      transforms.Resize((384, 384)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[.5], std=[.5])\n",
        "      ])\n",
        "\n",
        "    self.dataset = dataset\n",
        "    self.transform = T.ToPILImage()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image, label = self.dataset[idx]\n",
        "\n",
        "    if isinstance(image, torch.Tensor):\n",
        "          image = self.transform(image)\n",
        "\n",
        "    image = self.data_transform(image)\n",
        "\n",
        "    item = {'pixel_values' : image, 'labels' : label}\n",
        "    return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek_5G6nEbxxj",
        "outputId": "e7a39c34-0c90-4e83-b7da-57fdfed4fa94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Concatenating datasets\n",
            "Concatenating datasets\n",
            "Concatenating datasets\n"
          ]
        }
      ],
      "source": [
        "train_subset = 1080\n",
        "concat_dataset = ConcatDataset(path_dataset, derma_dataset, blood_dataset, retina_dataset, train_subset)\n",
        "#augmented_dataset = DatasetAugmentation(concat_dataset)\n",
        "train_dataset = CustomMNIST(concat_dataset)\n",
        "\n",
        "validation_subset = 120\n",
        "concat_val_dataset = ConcatDataset(val_path_dataset, val_derma_dataset, val_blood_dataset, val_retina_dataset, validation_subset)\n",
        "val_dataset = CustomMNIST(concat_val_dataset)\n",
        "\n",
        "test_subset = 400\n",
        "concat_test_dataset = ConcatDataset(test_path_dataset, test_derma_dataset, test_blood_dataset, test_retina_dataset, test_subset)\n",
        "test_dataset = CustomMNIST(concat_test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpNFjct8gwUe",
        "outputId": "130335a8-52f2-44f0-e906-36083bd9018c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4320\n",
            "480\n",
            "1600\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n",
        "print(len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id9PwRojeX_y"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpCr77yweWhv",
        "outputId": "c0a09f1d-69d3-449e-861c-d2245dd8425d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "feature_extractor = ViTHybridImageProcessor.from_pretrained('google/vit-hybrid-base-bit-384')\n",
        "baseline_model = ViTHybridForImageClassification.from_pretrained('google/vit-hybrid-base-bit-384')\n",
        "\n",
        "baseline_model.config.num_labels = num_labels\n",
        "\n",
        "\n",
        "model = ViTHybridForImageClassification.from_pretrained('google/vit-hybrid-base-bit-384')\n",
        "model.config.num_labels = num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AGkftpv1mKu_"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "batch_size = 32\n",
        "grad_accum = 1\n",
        "\n",
        "steps_per_epoch = math.ceil(\n",
        "    len(train_dataset)\n",
        "    / (batch_size * grad_accum)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khUt7UiWVDLw",
        "outputId": "6bceee37-65c0-4683-fffc-b0ae6b44e0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformers version --> 4.51.3\n",
            "TrainingArguments is defined in --> /usr/local/lib/python3.11/dist-packages/transformers/training_args.py\n"
          ]
        }
      ],
      "source": [
        "import transformers, inspect, textwrap, sys\n",
        "print(\"transformers version -->\", transformers.__version__)\n",
        "print(\"TrainingArguments is defined in -->\", inspect.getfile(transformers.TrainingArguments))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyper Parameter search and training of best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2V1Q4wk1gU3h"
      },
      "outputs": [],
      "source": [
        "accuracy_metric  = evaluate.load(\"accuracy\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric    = evaluate.load(\"recall\")\n",
        "f1_metric        = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "    accuracy  = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
        "    precision = precision_metric.compute(predictions=preds, references=labels, average=\"weighted\", zero_division=0)[\"precision\"]\n",
        "    recall    = recall_metric.compute(predictions=preds, references=labels, average=\"weighted\", zero_division=0)[\"recall\"]\n",
        "    f1        = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\":  accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\":    recall,\n",
        "        \"f1\":        f1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J8kHil8XrRUk",
        "outputId": "14961e49-2596-470f-d73c-4220b25a44b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 03:13:00,968] A new study created in memory with name: no-name-c7b6b6c1-b372-4d99-810f-8995c411015a\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmlabrie0208\u001b[0m (\u001b[33mmlabrie0208-polytechnique-montr-al\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_031303-a664c74p</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/a664c74p' target=\"_blank\">leafy-butterfly-17</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/a664c74p' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/a664c74p</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 31:38, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>7.049900</td>\n",
              "      <td>2.677499</td>\n",
              "      <td>0.329167</td>\n",
              "      <td>0.230275</td>\n",
              "      <td>0.329167</td>\n",
              "      <td>0.216303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.896700</td>\n",
              "      <td>1.217753</td>\n",
              "      <td>0.620833</td>\n",
              "      <td>0.555905</td>\n",
              "      <td>0.620833</td>\n",
              "      <td>0.558999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.173800</td>\n",
              "      <td>1.108192</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.655133</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.599274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.109300</td>\n",
              "      <td>0.888198</td>\n",
              "      <td>0.714583</td>\n",
              "      <td>0.729742</td>\n",
              "      <td>0.714583</td>\n",
              "      <td>0.683003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.046400</td>\n",
              "      <td>0.742728</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.647592</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.660843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.892500</td>\n",
              "      <td>0.844879</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.763615</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.702499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.832700</td>\n",
              "      <td>0.686212</td>\n",
              "      <td>0.729167</td>\n",
              "      <td>0.730831</td>\n",
              "      <td>0.729167</td>\n",
              "      <td>0.699415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.780700</td>\n",
              "      <td>0.758601</td>\n",
              "      <td>0.758333</td>\n",
              "      <td>0.792664</td>\n",
              "      <td>0.758333</td>\n",
              "      <td>0.731211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.714900</td>\n",
              "      <td>0.994456</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.738393</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.666551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.898200</td>\n",
              "      <td>0.769830</td>\n",
              "      <td>0.729167</td>\n",
              "      <td>0.769037</td>\n",
              "      <td>0.729167</td>\n",
              "      <td>0.715670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.690300</td>\n",
              "      <td>0.666609</td>\n",
              "      <td>0.754167</td>\n",
              "      <td>0.758745</td>\n",
              "      <td>0.754167</td>\n",
              "      <td>0.731056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.823000</td>\n",
              "      <td>0.688628</td>\n",
              "      <td>0.735417</td>\n",
              "      <td>0.765711</td>\n",
              "      <td>0.735417</td>\n",
              "      <td>0.698571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.730100</td>\n",
              "      <td>0.756547</td>\n",
              "      <td>0.754167</td>\n",
              "      <td>0.768628</td>\n",
              "      <td>0.754167</td>\n",
              "      <td>0.730336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.701200</td>\n",
              "      <td>0.613099</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.758045</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.749875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.611100</td>\n",
              "      <td>0.629460</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.720359</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.725297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.556900</td>\n",
              "      <td>0.595591</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.801624</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.771146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.576000</td>\n",
              "      <td>0.755877</td>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.705748</td>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.703257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.617800</td>\n",
              "      <td>0.595739</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.804894</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.773899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.657300</td>\n",
              "      <td>0.642017</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.764766</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.750529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.603000</td>\n",
              "      <td>0.636639</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.820771</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.761522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.502600</td>\n",
              "      <td>0.561513</td>\n",
              "      <td>0.772917</td>\n",
              "      <td>0.788822</td>\n",
              "      <td>0.772917</td>\n",
              "      <td>0.760394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.504200</td>\n",
              "      <td>0.589071</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.798330</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.796713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.465600</td>\n",
              "      <td>0.597688</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.791763</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.782815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.478300</td>\n",
              "      <td>0.581441</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.825333</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.796429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.394300</td>\n",
              "      <td>0.547473</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.817814</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.787883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.483000</td>\n",
              "      <td>0.623970</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.749928</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.729957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.529000</td>\n",
              "      <td>0.617127</td>\n",
              "      <td>0.777083</td>\n",
              "      <td>0.777320</td>\n",
              "      <td>0.777083</td>\n",
              "      <td>0.758093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.371000</td>\n",
              "      <td>0.589145</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.798962</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.784325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.320400</td>\n",
              "      <td>0.621171</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.818352</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.782834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.360100</td>\n",
              "      <td>0.534782</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.809476</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.793244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.327700</td>\n",
              "      <td>0.577608</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.796044</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.787908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.339500</td>\n",
              "      <td>0.526134</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.865034</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.818540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.295200</td>\n",
              "      <td>0.511821</td>\n",
              "      <td>0.829167</td>\n",
              "      <td>0.853972</td>\n",
              "      <td>0.829167</td>\n",
              "      <td>0.834355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.342900</td>\n",
              "      <td>0.558352</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.815796</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.805016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.222000</td>\n",
              "      <td>0.589174</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.796766</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.773859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.254800</td>\n",
              "      <td>0.572496</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.842722</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.819253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.238300</td>\n",
              "      <td>0.524829</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.822793</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.816833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.218600</td>\n",
              "      <td>0.551649</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.843346</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.829364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.519327</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.832794</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.822577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.175300</td>\n",
              "      <td>0.560150</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.838891</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.811788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.157200</td>\n",
              "      <td>0.604397</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.835276</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.824777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.107600</td>\n",
              "      <td>0.616770</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.832705</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.820064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.096100</td>\n",
              "      <td>0.636234</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.814995</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.806564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.084500</td>\n",
              "      <td>0.684813</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.829469</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.812664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.680953</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.835659</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.820638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.101500</td>\n",
              "      <td>0.740738</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.814349</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.795280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.122900</td>\n",
              "      <td>0.701650</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.851117</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.822380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.045500</td>\n",
              "      <td>0.727663</td>\n",
              "      <td>0.827083</td>\n",
              "      <td>0.830989</td>\n",
              "      <td>0.827083</td>\n",
              "      <td>0.825594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.030100</td>\n",
              "      <td>0.776439</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.832480</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.820529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.031100</td>\n",
              "      <td>0.844631</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.833189</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.816194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.014600</td>\n",
              "      <td>0.834558</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.830599</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.825754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.021500</td>\n",
              "      <td>0.865038</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.838268</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.819748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.862911</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.829262</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.819361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.029200</td>\n",
              "      <td>0.847355</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.843472</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.826261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.870143</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.842090</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.823700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>0.869517</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.839812</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.824352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.864833</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.840039</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.825064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.872677</td>\n",
              "      <td>0.827083</td>\n",
              "      <td>0.845492</td>\n",
              "      <td>0.827083</td>\n",
              "      <td>0.829806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.879186</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.848272</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.833198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.892846</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.844765</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.826075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.896008</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.842750</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.822673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.896275</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.841998</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.822433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.895091</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.840611</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.821953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.895450</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.840611</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.821953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.895147</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.842434</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.823977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.895038</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.842434</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.823977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.895107</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.842434</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.823977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 03:44:45,660] Trial 0 finished with value: 3.3080778600181313 and parameters: {'learning_rate': 8.935931938095857e-05, 'weight_decay': 0.04409991855514803, 'warmup_ratio': 0.03880873135635299}. Best is trial 0 with value: 3.3080778600181313.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.82083</td></tr><tr><td>eval/f1</td><td>0.82398</td></tr><tr><td>eval/loss</td><td>0.89511</td></tr><tr><td>eval/precision</td><td>0.84243</td></tr><tr><td>eval/recall</td><td>0.82083</td></tr><tr><td>eval/runtime</td><td>5.0598</td></tr><tr><td>eval/samples_per_second</td><td>94.865</td></tr><tr><td>eval/steps_per_second</td><td>11.858</td></tr><tr><td>total_flos</td><td>1.1345892843139891e+19</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>1350</td></tr><tr><td>train/grad_norm</td><td>0.04082</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0007</td></tr><tr><td>train_loss</td><td>0.45985</td></tr><tr><td>train_runtime</td><td>1902.6231</td></tr><tr><td>train_samples_per_second</td><td>22.705</td></tr><tr><td>train_steps_per_second</td><td>0.71</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">leafy-butterfly-17</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/a664c74p' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/a664c74p</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_031303-a664c74p/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_034448-td1azybf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/td1azybf' target=\"_blank\">radiant-planet-18</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/td1azybf' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/td1azybf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 31:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.350700</td>\n",
              "      <td>7.814697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>5.550800</td>\n",
              "      <td>2.707265</td>\n",
              "      <td>0.387500</td>\n",
              "      <td>0.272345</td>\n",
              "      <td>0.387500</td>\n",
              "      <td>0.299779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.103100</td>\n",
              "      <td>1.354396</td>\n",
              "      <td>0.568750</td>\n",
              "      <td>0.511076</td>\n",
              "      <td>0.568750</td>\n",
              "      <td>0.506690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.362400</td>\n",
              "      <td>1.063651</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.617565</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.605580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.146600</td>\n",
              "      <td>0.934574</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.713483</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.662477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.960600</td>\n",
              "      <td>0.906156</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.705060</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.669067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.866600</td>\n",
              "      <td>0.837076</td>\n",
              "      <td>0.685417</td>\n",
              "      <td>0.672451</td>\n",
              "      <td>0.685417</td>\n",
              "      <td>0.648302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.860800</td>\n",
              "      <td>0.860826</td>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.728046</td>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.713508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.794100</td>\n",
              "      <td>0.800713</td>\n",
              "      <td>0.714583</td>\n",
              "      <td>0.729262</td>\n",
              "      <td>0.714583</td>\n",
              "      <td>0.684242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.904000</td>\n",
              "      <td>0.970046</td>\n",
              "      <td>0.670833</td>\n",
              "      <td>0.772444</td>\n",
              "      <td>0.670833</td>\n",
              "      <td>0.671623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.790400</td>\n",
              "      <td>0.808127</td>\n",
              "      <td>0.716667</td>\n",
              "      <td>0.702756</td>\n",
              "      <td>0.716667</td>\n",
              "      <td>0.677656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.885300</td>\n",
              "      <td>0.730762</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.743622</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.708960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.732900</td>\n",
              "      <td>0.690546</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.767549</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.753169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.739400</td>\n",
              "      <td>0.625239</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.769307</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.767452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.601800</td>\n",
              "      <td>0.660274</td>\n",
              "      <td>0.754167</td>\n",
              "      <td>0.782744</td>\n",
              "      <td>0.754167</td>\n",
              "      <td>0.744247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.527200</td>\n",
              "      <td>0.570661</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.759772</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.758447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.549300</td>\n",
              "      <td>0.751496</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.776672</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.732414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.690700</td>\n",
              "      <td>0.677467</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.769610</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.736466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.689300</td>\n",
              "      <td>0.601838</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.781113</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.766189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.607700</td>\n",
              "      <td>0.633847</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.739145</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.722566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.515200</td>\n",
              "      <td>0.560838</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.779786</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.771198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.492900</td>\n",
              "      <td>0.584136</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.801596</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.776849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.481500</td>\n",
              "      <td>0.638963</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.762723</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.756180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.475100</td>\n",
              "      <td>0.562366</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.872756</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.803911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.386400</td>\n",
              "      <td>0.568262</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800697</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.787725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.482900</td>\n",
              "      <td>0.670860</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.831140</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.762019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.458300</td>\n",
              "      <td>0.585045</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.801081</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.786006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.329600</td>\n",
              "      <td>0.547552</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.804438</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.807532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.270100</td>\n",
              "      <td>0.618443</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.827129</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.806112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.331900</td>\n",
              "      <td>0.615911</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.771170</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.771994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.309200</td>\n",
              "      <td>0.615276</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.788173</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.779397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.336500</td>\n",
              "      <td>0.602253</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.807000</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.777698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.294600</td>\n",
              "      <td>0.611202</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.804492</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.795061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.318500</td>\n",
              "      <td>0.548735</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.822261</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.813615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.661526</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.783365</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.769064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.225900</td>\n",
              "      <td>0.629768</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.775059</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.780165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.183400</td>\n",
              "      <td>0.617280</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.824524</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.806853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.208300</td>\n",
              "      <td>0.714307</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.783125</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.783303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.220100</td>\n",
              "      <td>0.669380</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.779288</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.152100</td>\n",
              "      <td>0.651224</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.801966</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.799495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.186900</td>\n",
              "      <td>0.642827</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.834612</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.822578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.083100</td>\n",
              "      <td>0.721460</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.812111</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.807142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.080200</td>\n",
              "      <td>0.737735</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.798317</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.797905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.063500</td>\n",
              "      <td>0.792973</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.807449</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.800511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.108400</td>\n",
              "      <td>0.741087</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.827605</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.820185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.086000</td>\n",
              "      <td>0.771017</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.837342</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.822697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.088300</td>\n",
              "      <td>0.783786</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.847083</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.825638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.045400</td>\n",
              "      <td>0.764145</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.816960</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.807877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>0.824533</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.830757</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.815130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.019300</td>\n",
              "      <td>0.831024</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.841939</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.818556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.017800</td>\n",
              "      <td>0.841608</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.834136</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.821814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.018900</td>\n",
              "      <td>0.866116</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.823237</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.810993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.022000</td>\n",
              "      <td>0.863347</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.814908</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.809385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.022900</td>\n",
              "      <td>0.903673</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.828626</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.814075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.871764</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.831581</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.816668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.882255</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.817002</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.810635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.888808</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.812789</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.808310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.922968</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.820307</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.807679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.926590</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.818004</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.810185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.927559</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.827470</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.819767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.923047</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.832687</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.823871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.923460</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.830835</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.821787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.923446</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.828857</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.819845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.923971</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.830835</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.821787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.924561</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.830835</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.821787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.924904</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.830835</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.821787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.924917</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.830835</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.821787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 04:16:44,413] Trial 1 finished with value: 3.298455792850545 and parameters: {'learning_rate': 4.128541444974793e-05, 'weight_decay': 0.06564430990679145, 'warmup_ratio': 0.13432837969102687}. Best is trial 0 with value: 3.3080778600181313.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.82292</td></tr><tr><td>eval/f1</td><td>0.82179</td></tr><tr><td>eval/loss</td><td>0.92492</td></tr><tr><td>eval/precision</td><td>0.83084</td></tr><tr><td>eval/recall</td><td>0.82292</td></tr><tr><td>eval/runtime</td><td>5.2241</td></tr><tr><td>eval/samples_per_second</td><td>91.882</td></tr><tr><td>eval/steps_per_second</td><td>11.485</td></tr><tr><td>total_flos</td><td>1.1345892843139891e+19</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>1350</td></tr><tr><td>train/grad_norm</td><td>0.1147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0011</td></tr><tr><td>train_loss</td><td>0.56683</td></tr><tr><td>train_runtime</td><td>1916.5328</td></tr><tr><td>train_samples_per_second</td><td>22.541</td></tr><tr><td>train_steps_per_second</td><td>0.704</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">radiant-planet-18</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/td1azybf' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/td1azybf</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_034448-td1azybf/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_041647-kd6w0m8x</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kd6w0m8x' target=\"_blank\">devoted-pine-19</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kd6w0m8x' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kd6w0m8x</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 31:58, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.428400</td>\n",
              "      <td>8.064909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>6.020500</td>\n",
              "      <td>3.229142</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.307888</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.299193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.333700</td>\n",
              "      <td>1.490505</td>\n",
              "      <td>0.527083</td>\n",
              "      <td>0.556564</td>\n",
              "      <td>0.527083</td>\n",
              "      <td>0.495847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.421100</td>\n",
              "      <td>1.091535</td>\n",
              "      <td>0.635417</td>\n",
              "      <td>0.600647</td>\n",
              "      <td>0.635417</td>\n",
              "      <td>0.589452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.154600</td>\n",
              "      <td>0.973702</td>\n",
              "      <td>0.685417</td>\n",
              "      <td>0.668731</td>\n",
              "      <td>0.685417</td>\n",
              "      <td>0.637237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.969000</td>\n",
              "      <td>0.918111</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.725690</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.684580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.877600</td>\n",
              "      <td>0.804076</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.680425</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.670737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.847800</td>\n",
              "      <td>0.857801</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.711606</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.702099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.806800</td>\n",
              "      <td>0.873656</td>\n",
              "      <td>0.697917</td>\n",
              "      <td>0.700376</td>\n",
              "      <td>0.697917</td>\n",
              "      <td>0.667560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.979000</td>\n",
              "      <td>0.876673</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.749601</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.693425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.803400</td>\n",
              "      <td>0.820379</td>\n",
              "      <td>0.727083</td>\n",
              "      <td>0.726049</td>\n",
              "      <td>0.727083</td>\n",
              "      <td>0.693009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.890100</td>\n",
              "      <td>0.724368</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.682873</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.687643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.773800</td>\n",
              "      <td>0.725482</td>\n",
              "      <td>0.764583</td>\n",
              "      <td>0.780066</td>\n",
              "      <td>0.764583</td>\n",
              "      <td>0.756684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.819800</td>\n",
              "      <td>0.646747</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.783739</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.727532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.629300</td>\n",
              "      <td>0.684689</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.775873</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.752314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.611266</td>\n",
              "      <td>0.764583</td>\n",
              "      <td>0.735191</td>\n",
              "      <td>0.764583</td>\n",
              "      <td>0.731176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.626200</td>\n",
              "      <td>0.716635</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.784174</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.725431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.727700</td>\n",
              "      <td>0.684166</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.736646</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.729226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.712000</td>\n",
              "      <td>0.721034</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.730415</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.690431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.634400</td>\n",
              "      <td>0.594857</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.744271</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.726955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.531000</td>\n",
              "      <td>0.590677</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.788401</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.762657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.597600</td>\n",
              "      <td>0.698385</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.798738</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.748589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.462200</td>\n",
              "      <td>0.633224</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.778093</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.753697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.501900</td>\n",
              "      <td>0.591511</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.820663</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.784102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.414300</td>\n",
              "      <td>0.547801</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.829575</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.811348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.496200</td>\n",
              "      <td>0.641267</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.737442</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.729243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.509600</td>\n",
              "      <td>0.591229</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.799617</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.770302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.389500</td>\n",
              "      <td>0.577535</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.780869</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.772911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.329600</td>\n",
              "      <td>0.684440</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.795345</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.771665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.373800</td>\n",
              "      <td>0.624625</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.801938</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.786998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.352500</td>\n",
              "      <td>0.534873</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.819112</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.796716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.360400</td>\n",
              "      <td>0.623038</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.815898</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.772112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.311500</td>\n",
              "      <td>0.547102</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.810515</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.793907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.341000</td>\n",
              "      <td>0.632296</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.816208</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.798048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.669293</td>\n",
              "      <td>0.772917</td>\n",
              "      <td>0.796454</td>\n",
              "      <td>0.772917</td>\n",
              "      <td>0.761850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.250300</td>\n",
              "      <td>0.627237</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.822831</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.796072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.235100</td>\n",
              "      <td>0.595742</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.813756</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.792346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.232500</td>\n",
              "      <td>0.646901</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.804683</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.791055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.245900</td>\n",
              "      <td>0.674454</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.814542</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.789492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.192100</td>\n",
              "      <td>0.633391</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.836216</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.800404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.195300</td>\n",
              "      <td>0.601651</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.800354</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.799206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.132300</td>\n",
              "      <td>0.640007</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.850981</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.819952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.117300</td>\n",
              "      <td>0.664015</td>\n",
              "      <td>0.827083</td>\n",
              "      <td>0.823312</td>\n",
              "      <td>0.827083</td>\n",
              "      <td>0.820049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>0.708212</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.834817</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.813920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.144300</td>\n",
              "      <td>0.719356</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.826054</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.805788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.118600</td>\n",
              "      <td>0.801597</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.841930</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.807950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.123200</td>\n",
              "      <td>0.716640</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.824794</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.810968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.042400</td>\n",
              "      <td>0.732963</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.824764</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.816566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.030600</td>\n",
              "      <td>0.839928</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.849506</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.827176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.028900</td>\n",
              "      <td>0.864275</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.810261</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.801051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.029700</td>\n",
              "      <td>0.824484</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.818037</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.811252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.040800</td>\n",
              "      <td>0.872893</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.832159</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.817784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.876134</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.816856</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.809560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.040100</td>\n",
              "      <td>0.868699</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.835700</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.816676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.004800</td>\n",
              "      <td>0.862903</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.829596</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.813839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.872640</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.835310</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.816567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.002600</td>\n",
              "      <td>0.881368</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.827110</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.812889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>0.902571</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.830640</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.813472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.928060</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.828941</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.809524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>0.933920</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.832057</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.814976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.922046</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.830676</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.815866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.923384</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.824992</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.811506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.924970</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.829085</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.815541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.926391</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.829085</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.815541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.927235</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.829085</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.815541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.927464</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.829085</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.815541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.927515</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.829085</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.815541</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 04:48:49,741] Trial 2 finished with value: 3.273792992727566 and parameters: {'learning_rate': 4.988228793690131e-05, 'weight_decay': 0.04826862762367262, 'warmup_ratio': 0.18948914479708076}. Best is trial 0 with value: 3.3080778600181313.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.81458</td></tr><tr><td>eval/f1</td><td>0.81554</td></tr><tr><td>eval/loss</td><td>0.92752</td></tr><tr><td>eval/precision</td><td>0.82908</td></tr><tr><td>eval/recall</td><td>0.81458</td></tr><tr><td>eval/runtime</td><td>5.1624</td></tr><tr><td>eval/samples_per_second</td><td>92.981</td></tr><tr><td>eval/steps_per_second</td><td>11.623</td></tr><tr><td>total_flos</td><td>1.1345892843139891e+19</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>1350</td></tr><tr><td>train/grad_norm</td><td>0.01482</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0022</td></tr><tr><td>train_loss</td><td>0.60169</td></tr><tr><td>train_runtime</td><td>1922.7409</td></tr><tr><td>train_samples_per_second</td><td>22.468</td></tr><tr><td>train_steps_per_second</td><td>0.702</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">devoted-pine-19</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kd6w0m8x' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kd6w0m8x</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_041647-kd6w0m8x/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_044852-kbspue3m</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kbspue3m' target=\"_blank\">frosty-grass-20</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kbspue3m' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kbspue3m</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 31:56, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>8.369700</td>\n",
              "      <td>4.732714</td>\n",
              "      <td>0.137500</td>\n",
              "      <td>0.285318</td>\n",
              "      <td>0.137500</td>\n",
              "      <td>0.140785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.653000</td>\n",
              "      <td>1.480433</td>\n",
              "      <td>0.535417</td>\n",
              "      <td>0.504207</td>\n",
              "      <td>0.535417</td>\n",
              "      <td>0.487349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.387400</td>\n",
              "      <td>1.036163</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.610691</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.606839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.125100</td>\n",
              "      <td>0.905093</td>\n",
              "      <td>0.677083</td>\n",
              "      <td>0.664700</td>\n",
              "      <td>0.677083</td>\n",
              "      <td>0.645982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.999300</td>\n",
              "      <td>0.809509</td>\n",
              "      <td>0.747917</td>\n",
              "      <td>0.725761</td>\n",
              "      <td>0.747917</td>\n",
              "      <td>0.712347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.876100</td>\n",
              "      <td>0.758909</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.729669</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.688149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.781200</td>\n",
              "      <td>0.745523</td>\n",
              "      <td>0.729167</td>\n",
              "      <td>0.738913</td>\n",
              "      <td>0.729167</td>\n",
              "      <td>0.712383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.753500</td>\n",
              "      <td>0.764445</td>\n",
              "      <td>0.720833</td>\n",
              "      <td>0.740099</td>\n",
              "      <td>0.720833</td>\n",
              "      <td>0.703458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.779600</td>\n",
              "      <td>0.919013</td>\n",
              "      <td>0.720833</td>\n",
              "      <td>0.753616</td>\n",
              "      <td>0.720833</td>\n",
              "      <td>0.711338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.776800</td>\n",
              "      <td>0.713302</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.802408</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.759184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.643400</td>\n",
              "      <td>0.695817</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.774242</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.754028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.731500</td>\n",
              "      <td>0.656136</td>\n",
              "      <td>0.745833</td>\n",
              "      <td>0.756971</td>\n",
              "      <td>0.745833</td>\n",
              "      <td>0.726566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.601700</td>\n",
              "      <td>0.621650</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.760704</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.752248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.627377</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.774678</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.741825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.533200</td>\n",
              "      <td>0.635646</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.760236</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.733146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.463700</td>\n",
              "      <td>0.593115</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.770890</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.758134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.522100</td>\n",
              "      <td>0.586162</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.770861</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.749645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.599500</td>\n",
              "      <td>0.669851</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.830304</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.793495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.585100</td>\n",
              "      <td>0.582554</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.807774</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.804807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.511000</td>\n",
              "      <td>0.629146</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.793769</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.782298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.446900</td>\n",
              "      <td>0.619153</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.781398</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.769642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.447600</td>\n",
              "      <td>0.606012</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.789746</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.783495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.399500</td>\n",
              "      <td>0.570907</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.775783</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.777717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.431100</td>\n",
              "      <td>0.593229</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.829613</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.790543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.341600</td>\n",
              "      <td>0.606476</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.797028</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.783034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.412500</td>\n",
              "      <td>0.616690</td>\n",
              "      <td>0.777083</td>\n",
              "      <td>0.782741</td>\n",
              "      <td>0.777083</td>\n",
              "      <td>0.768443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.399300</td>\n",
              "      <td>0.602526</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.794119</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.784529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.313100</td>\n",
              "      <td>0.619584</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.774661</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.767026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.269300</td>\n",
              "      <td>0.589017</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.811909</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.798900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.280600</td>\n",
              "      <td>0.629012</td>\n",
              "      <td>0.777083</td>\n",
              "      <td>0.753078</td>\n",
              "      <td>0.777083</td>\n",
              "      <td>0.758171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.298000</td>\n",
              "      <td>0.599812</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.799288</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.794594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.599331</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.816620</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.807408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.267400</td>\n",
              "      <td>0.608863</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.807558</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.797122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.273400</td>\n",
              "      <td>0.637054</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.818295</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.792578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.182300</td>\n",
              "      <td>0.649078</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.774628</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.770269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.233100</td>\n",
              "      <td>0.656546</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.798876</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.784128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.188600</td>\n",
              "      <td>0.629542</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.828452</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.819249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.183800</td>\n",
              "      <td>0.664035</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.797340</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.791394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.208200</td>\n",
              "      <td>0.619097</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.801267</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.799716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.173800</td>\n",
              "      <td>0.645515</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.812976</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.803634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.182600</td>\n",
              "      <td>0.657562</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.839147</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.825727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.142000</td>\n",
              "      <td>0.682971</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.817050</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.807355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.115300</td>\n",
              "      <td>0.737785</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.795018</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.788546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.113700</td>\n",
              "      <td>0.652008</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.807587</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.152200</td>\n",
              "      <td>0.685087</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.809717</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.802395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.113900</td>\n",
              "      <td>0.725601</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.825515</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.812372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.123700</td>\n",
              "      <td>0.701927</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.813068</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.806639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.079000</td>\n",
              "      <td>0.712669</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.795041</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.789032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.076200</td>\n",
              "      <td>0.754492</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.813782</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.804566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.052200</td>\n",
              "      <td>0.771080</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.794104</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.787998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>0.797009</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.808999</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.793783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.065600</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.800848</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.793670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.075700</td>\n",
              "      <td>0.781860</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.797385</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.791139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.081200</td>\n",
              "      <td>0.791368</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.811685</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.798821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.041800</td>\n",
              "      <td>0.795037</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.801541</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.789552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.037200</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.804283</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.795757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.032100</td>\n",
              "      <td>0.799650</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.801157</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.794689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.031400</td>\n",
              "      <td>0.804231</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.809081</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.031200</td>\n",
              "      <td>0.807205</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.804641</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.798568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.035000</td>\n",
              "      <td>0.819051</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.809568</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.801736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.031700</td>\n",
              "      <td>0.827675</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.816109</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.804821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.019500</td>\n",
              "      <td>0.817615</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.812049</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.803512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.815040</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.812189</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.802933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.024200</td>\n",
              "      <td>0.818100</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.812189</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.802933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.818443</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.812189</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.802933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.021300</td>\n",
              "      <td>0.819099</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.812189</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.802933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.027800</td>\n",
              "      <td>0.819161</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.812189</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.802933</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 05:20:52,799] Trial 3 finished with value: 3.2192894128684864 and parameters: {'learning_rate': 1.375631455682336e-05, 'weight_decay': 0.0909356016505414, 'warmup_ratio': 0.013914281029703046}. Best is trial 0 with value: 3.3080778600181313.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.80208</td></tr><tr><td>eval/f1</td><td>0.80293</td></tr><tr><td>eval/loss</td><td>0.81916</td></tr><tr><td>eval/precision</td><td>0.81219</td></tr><tr><td>eval/recall</td><td>0.80208</td></tr><tr><td>eval/runtime</td><td>5.1423</td></tr><tr><td>eval/samples_per_second</td><td>93.343</td></tr><tr><td>eval/steps_per_second</td><td>11.668</td></tr><tr><td>total_flos</td><td>1.1345892843139891e+19</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>1350</td></tr><tr><td>train/grad_norm</td><td>3.78598</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0278</td></tr><tr><td>train_loss</td><td>0.47653</td></tr><tr><td>train_runtime</td><td>1920.794</td></tr><tr><td>train_samples_per_second</td><td>22.491</td></tr><tr><td>train_steps_per_second</td><td>0.703</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">frosty-grass-20</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kbspue3m' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/kbspue3m</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_044852-kbspue3m/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_052056-03ytmmjg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/03ytmmjg' target=\"_blank\">hopeful-resonance-21</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/03ytmmjg' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/03ytmmjg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 31:58, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.743400</td>\n",
              "      <td>9.136816</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>8.067700</td>\n",
              "      <td>6.734937</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>5.180100</td>\n",
              "      <td>3.168143</td>\n",
              "      <td>0.354167</td>\n",
              "      <td>0.273261</td>\n",
              "      <td>0.354167</td>\n",
              "      <td>0.292777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.508900</td>\n",
              "      <td>1.723818</td>\n",
              "      <td>0.510417</td>\n",
              "      <td>0.467416</td>\n",
              "      <td>0.510417</td>\n",
              "      <td>0.455537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.702800</td>\n",
              "      <td>1.254721</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0.587015</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0.552440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.203000</td>\n",
              "      <td>1.011370</td>\n",
              "      <td>0.660417</td>\n",
              "      <td>0.652043</td>\n",
              "      <td>0.660417</td>\n",
              "      <td>0.622863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.977700</td>\n",
              "      <td>0.894174</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.678602</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.678395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.911900</td>\n",
              "      <td>0.874865</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.727703</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.699251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.929000</td>\n",
              "      <td>0.959769</td>\n",
              "      <td>0.702083</td>\n",
              "      <td>0.735885</td>\n",
              "      <td>0.702083</td>\n",
              "      <td>0.696970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.921700</td>\n",
              "      <td>0.788978</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.776056</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.729397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.750100</td>\n",
              "      <td>0.729491</td>\n",
              "      <td>0.747917</td>\n",
              "      <td>0.743634</td>\n",
              "      <td>0.747917</td>\n",
              "      <td>0.723826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.828900</td>\n",
              "      <td>0.751978</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.688308</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.678983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.703200</td>\n",
              "      <td>0.648359</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.750759</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.731597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.669700</td>\n",
              "      <td>0.664277</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.774794</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.749398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.596600</td>\n",
              "      <td>0.677359</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.759274</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.732838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.500200</td>\n",
              "      <td>0.609101</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.766514</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.762577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.541600</td>\n",
              "      <td>0.617869</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.751656</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.745118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.647100</td>\n",
              "      <td>0.682645</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.804102</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.764792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.621500</td>\n",
              "      <td>0.639188</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.790276</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.782735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.585100</td>\n",
              "      <td>0.626649</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.789816</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.770603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.459500</td>\n",
              "      <td>0.646556</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.754693</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.753447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.483400</td>\n",
              "      <td>0.644984</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.790404</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.770201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.454500</td>\n",
              "      <td>0.594335</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.792069</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.781392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.468400</td>\n",
              "      <td>0.639794</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.793898</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.773369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.379300</td>\n",
              "      <td>0.625697</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.798103</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.788166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.451700</td>\n",
              "      <td>0.632252</td>\n",
              "      <td>0.772917</td>\n",
              "      <td>0.778142</td>\n",
              "      <td>0.772917</td>\n",
              "      <td>0.759934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.647469</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.751359</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.750523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.362700</td>\n",
              "      <td>0.629237</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.767751</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.766287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.297900</td>\n",
              "      <td>0.614604</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.794407</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.790339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.294800</td>\n",
              "      <td>0.628478</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.761029</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.770105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.316400</td>\n",
              "      <td>0.594062</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.800506</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.795850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.319600</td>\n",
              "      <td>0.624177</td>\n",
              "      <td>0.777083</td>\n",
              "      <td>0.786268</td>\n",
              "      <td>0.777083</td>\n",
              "      <td>0.772555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.291300</td>\n",
              "      <td>0.611901</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.798960</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.791925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.276400</td>\n",
              "      <td>0.633624</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.795774</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.790126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.194800</td>\n",
              "      <td>0.664358</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.783101</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.765461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.235600</td>\n",
              "      <td>0.644963</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.811168</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.798825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.218100</td>\n",
              "      <td>0.622611</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.820222</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.814438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.221800</td>\n",
              "      <td>0.643026</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.808077</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.807851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.220700</td>\n",
              "      <td>0.655813</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.818781</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.813836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.197300</td>\n",
              "      <td>0.648122</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.826434</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.815120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.177400</td>\n",
              "      <td>0.677310</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.820088</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.808625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.128300</td>\n",
              "      <td>0.723212</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.826628</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.812048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.798341</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.791287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.111700</td>\n",
              "      <td>0.744315</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.806771</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.795645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.727436</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.810619</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.802731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.116800</td>\n",
              "      <td>0.745761</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.813606</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.806781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.131400</td>\n",
              "      <td>0.745440</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.824518</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.813640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.077000</td>\n",
              "      <td>0.761694</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.800978</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.795927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.071900</td>\n",
              "      <td>0.797575</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.812509</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.806958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.048700</td>\n",
              "      <td>0.830961</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.793577</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.790440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.045800</td>\n",
              "      <td>0.842498</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.797597</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.796184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.062400</td>\n",
              "      <td>0.823020</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.806715</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.801507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.066600</td>\n",
              "      <td>0.825208</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.812564</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.806592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.071800</td>\n",
              "      <td>0.828788</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.811851</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.805768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.030200</td>\n",
              "      <td>0.839986</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.816704</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.809724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.030200</td>\n",
              "      <td>0.852456</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.817017</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.811784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.022600</td>\n",
              "      <td>0.860036</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.809449</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.805220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.032400</td>\n",
              "      <td>0.846477</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.809014</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.804859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.024800</td>\n",
              "      <td>0.867060</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.809043</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.805143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.027900</td>\n",
              "      <td>0.879072</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.805905</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.798094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.021700</td>\n",
              "      <td>0.884685</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.804785</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.796269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.873344</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.804533</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.015100</td>\n",
              "      <td>0.875964</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.806182</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.015100</td>\n",
              "      <td>0.879202</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.804230</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.798148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.014200</td>\n",
              "      <td>0.878900</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.804230</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.798148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.013700</td>\n",
              "      <td>0.878770</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.804230</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.798148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.023200</td>\n",
              "      <td>0.878893</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.804230</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.798148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 05:52:57,815] Trial 4 finished with value: 3.1982111700073785 and parameters: {'learning_rate': 1.3384550345036935e-05, 'weight_decay': 0.09300766188298723, 'warmup_ratio': 0.12710949564138083}. Best is trial 0 with value: 3.3080778600181313.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.79792</td></tr><tr><td>eval/f1</td><td>0.79815</td></tr><tr><td>eval/loss</td><td>0.87889</td></tr><tr><td>eval/precision</td><td>0.80423</td></tr><tr><td>eval/recall</td><td>0.79792</td></tr><tr><td>eval/runtime</td><td>5.1458</td></tr><tr><td>eval/samples_per_second</td><td>93.279</td></tr><tr><td>eval/steps_per_second</td><td>11.66</td></tr><tr><td>total_flos</td><td>1.1345892843139891e+19</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>1350</td></tr><tr><td>train/grad_norm</td><td>3.06082</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0232</td></tr><tr><td>train_loss</td><td>0.69423</td></tr><tr><td>train_runtime</td><td>1922.8291</td></tr><tr><td>train_samples_per_second</td><td>22.467</td></tr><tr><td>train_steps_per_second</td><td>0.702</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hopeful-resonance-21</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/03ytmmjg' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/03ytmmjg</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_052056-03ytmmjg/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_055301-scb7a40k</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/scb7a40k' target=\"_blank\">honest-deluge-22</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/scb7a40k' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/scb7a40k</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  40/1350 00:55 < 32:03, 0.68 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.374000</td>\n",
              "      <td>7.888823</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>5.687200</td>\n",
              "      <td>2.839449</td>\n",
              "      <td>0.377083</td>\n",
              "      <td>0.268042</td>\n",
              "      <td>0.377083</td>\n",
              "      <td>0.293736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 05:53:59,466] Trial 5 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.37708</td></tr><tr><td>eval/f1</td><td>0.29374</td></tr><tr><td>eval/loss</td><td>2.83945</td></tr><tr><td>eval/precision</td><td>0.26804</td></tr><tr><td>eval/recall</td><td>0.37708</td></tr><tr><td>eval/runtime</td><td>5.2078</td></tr><tr><td>eval/samples_per_second</td><td>92.169</td></tr><tr><td>eval/steps_per_second</td><td>11.521</td></tr><tr><td>train/epoch</td><td>0.2963</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>17.25177</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>5.6872</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">honest-deluge-22</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/scb7a40k' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/scb7a40k</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_055301-scb7a40k/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_055402-utl9b0qf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/utl9b0qf' target=\"_blank\">whole-surf-23</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/utl9b0qf' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/utl9b0qf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  40/1350 00:55 < 32:03, 0.68 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.529600</td>\n",
              "      <td>8.398238</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>6.666400</td>\n",
              "      <td>4.249841</td>\n",
              "      <td>0.204167</td>\n",
              "      <td>0.292200</td>\n",
              "      <td>0.204167</td>\n",
              "      <td>0.195825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 05:55:00,265] Trial 6 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.20417</td></tr><tr><td>eval/f1</td><td>0.19582</td></tr><tr><td>eval/loss</td><td>4.24984</td></tr><tr><td>eval/precision</td><td>0.2922</td></tr><tr><td>eval/recall</td><td>0.20417</td></tr><tr><td>eval/runtime</td><td>5.1042</td></tr><tr><td>eval/samples_per_second</td><td>94.04</td></tr><tr><td>eval/steps_per_second</td><td>11.755</td></tr><tr><td>train/epoch</td><td>0.2963</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>20.0865</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>6.6664</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">whole-surf-23</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/utl9b0qf' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/utl9b0qf</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_055402-utl9b0qf/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_055502-g2i6emr7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/g2i6emr7' target=\"_blank\">electric-fire-24</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/g2i6emr7' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/g2i6emr7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  40/1350 00:55 < 31:59, 0.68 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.401600</td>\n",
              "      <td>7.977735</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>5.854200</td>\n",
              "      <td>3.021795</td>\n",
              "      <td>0.379167</td>\n",
              "      <td>0.271987</td>\n",
              "      <td>0.379167</td>\n",
              "      <td>0.299178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 05:56:01,000] Trial 7 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.37917</td></tr><tr><td>eval/f1</td><td>0.29918</td></tr><tr><td>eval/loss</td><td>3.02179</td></tr><tr><td>eval/precision</td><td>0.27199</td></tr><tr><td>eval/recall</td><td>0.37917</td></tr><tr><td>eval/runtime</td><td>5.1319</td></tr><tr><td>eval/samples_per_second</td><td>93.532</td></tr><tr><td>eval/steps_per_second</td><td>11.692</td></tr><tr><td>train/epoch</td><td>0.2963</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>17.82023</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>5.8542</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">electric-fire-24</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/g2i6emr7' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/g2i6emr7</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_055502-g2i6emr7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_055604-d9a40r3w</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/d9a40r3w' target=\"_blank\">autumn-pond-25</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/d9a40r3w' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/d9a40r3w</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  80/1350 01:52 < 30:36, 0.69 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.187200</td>\n",
              "      <td>7.300386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>4.696400</td>\n",
              "      <td>2.181925</td>\n",
              "      <td>0.414583</td>\n",
              "      <td>0.348045</td>\n",
              "      <td>0.414583</td>\n",
              "      <td>0.331924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.807100</td>\n",
              "      <td>1.208013</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.576458</td>\n",
              "      <td>0.643750</td>\n",
              "      <td>0.574125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.242700</td>\n",
              "      <td>1.024961</td>\n",
              "      <td>0.629167</td>\n",
              "      <td>0.636359</td>\n",
              "      <td>0.629167</td>\n",
              "      <td>0.597511</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 05:57:59,493] Trial 8 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.62917</td></tr><tr><td>eval/f1</td><td>0.59751</td></tr><tr><td>eval/loss</td><td>1.02496</td></tr><tr><td>eval/precision</td><td>0.63636</td></tr><tr><td>eval/recall</td><td>0.62917</td></tr><tr><td>eval/runtime</td><td>5.2984</td></tr><tr><td>eval/samples_per_second</td><td>90.593</td></tr><tr><td>eval/steps_per_second</td><td>11.324</td></tr><tr><td>train/epoch</td><td>0.59259</td></tr><tr><td>train/global_step</td><td>80</td></tr><tr><td>train/grad_norm</td><td>12.65756</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.2427</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">autumn-pond-25</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/d9a40r3w' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/d9a40r3w</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_055604-d9a40r3w/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_055803-j8fybzas</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/j8fybzas' target=\"_blank\">whole-eon-26</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/j8fybzas' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/j8fybzas</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 260/1350 06:08 < 25:56, 0.70 it/s, Epoch 1/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.233800</td>\n",
              "      <td>7.445715</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>4.918600</td>\n",
              "      <td>2.275624</td>\n",
              "      <td>0.397917</td>\n",
              "      <td>0.346714</td>\n",
              "      <td>0.397917</td>\n",
              "      <td>0.314989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.870800</td>\n",
              "      <td>1.264107</td>\n",
              "      <td>0.641667</td>\n",
              "      <td>0.590326</td>\n",
              "      <td>0.641667</td>\n",
              "      <td>0.572203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.253200</td>\n",
              "      <td>1.017486</td>\n",
              "      <td>0.639583</td>\n",
              "      <td>0.655221</td>\n",
              "      <td>0.639583</td>\n",
              "      <td>0.609502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.087900</td>\n",
              "      <td>0.870690</td>\n",
              "      <td>0.727083</td>\n",
              "      <td>0.684175</td>\n",
              "      <td>0.727083</td>\n",
              "      <td>0.681755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.910800</td>\n",
              "      <td>0.800990</td>\n",
              "      <td>0.720833</td>\n",
              "      <td>0.745310</td>\n",
              "      <td>0.720833</td>\n",
              "      <td>0.693866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.809200</td>\n",
              "      <td>0.740559</td>\n",
              "      <td>0.735417</td>\n",
              "      <td>0.751536</td>\n",
              "      <td>0.735417</td>\n",
              "      <td>0.719674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.770600</td>\n",
              "      <td>0.761774</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.758908</td>\n",
              "      <td>0.731250</td>\n",
              "      <td>0.721570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.828900</td>\n",
              "      <td>0.910197</td>\n",
              "      <td>0.714583</td>\n",
              "      <td>0.756229</td>\n",
              "      <td>0.714583</td>\n",
              "      <td>0.707083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.802700</td>\n",
              "      <td>0.724654</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.795149</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.743676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.661100</td>\n",
              "      <td>0.724402</td>\n",
              "      <td>0.756250</td>\n",
              "      <td>0.760196</td>\n",
              "      <td>0.756250</td>\n",
              "      <td>0.740074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.740800</td>\n",
              "      <td>0.658019</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.738126</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.713636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.613300</td>\n",
              "      <td>0.643538</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.758925</td>\n",
              "      <td>0.768750</td>\n",
              "      <td>0.749834</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:04:14,035] Trial 9 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.76875</td></tr><tr><td>eval/f1</td><td>0.74983</td></tr><tr><td>eval/loss</td><td>0.64354</td></tr><tr><td>eval/precision</td><td>0.75892</td></tr><tr><td>eval/recall</td><td>0.76875</td></tr><tr><td>eval/runtime</td><td>5.1498</td></tr><tr><td>eval/samples_per_second</td><td>93.207</td></tr><tr><td>eval/steps_per_second</td><td>11.651</td></tr><tr><td>train/epoch</td><td>1.92593</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/grad_norm</td><td>10.37358</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.6133</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">whole-eon-26</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/j8fybzas' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/j8fybzas</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_055803-j8fybzas/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_060417-mt7uf0o4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/mt7uf0o4' target=\"_blank\">visionary-hill-27</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/mt7uf0o4' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/mt7uf0o4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 100/1350 02:20 < 29:57, 0.70 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>6.161600</td>\n",
              "      <td>2.157657</td>\n",
              "      <td>0.389583</td>\n",
              "      <td>0.357239</td>\n",
              "      <td>0.389583</td>\n",
              "      <td>0.323717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.625600</td>\n",
              "      <td>1.132435</td>\n",
              "      <td>0.635417</td>\n",
              "      <td>0.672750</td>\n",
              "      <td>0.635417</td>\n",
              "      <td>0.601363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.177300</td>\n",
              "      <td>1.198568</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.667881</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.635256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.235600</td>\n",
              "      <td>1.218571</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.638503</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.589600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.266200</td>\n",
              "      <td>0.999938</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.606797</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.604644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:06:40,959] Trial 10 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.67917</td></tr><tr><td>eval/f1</td><td>0.60464</td></tr><tr><td>eval/loss</td><td>0.99994</td></tr><tr><td>eval/precision</td><td>0.6068</td></tr><tr><td>eval/recall</td><td>0.67917</td></tr><tr><td>eval/runtime</td><td>5.0938</td></tr><tr><td>eval/samples_per_second</td><td>94.232</td></tr><tr><td>eval/steps_per_second</td><td>11.779</td></tr><tr><td>train/epoch</td><td>0.74074</td></tr><tr><td>train/global_step</td><td>100</td></tr><tr><td>train/grad_norm</td><td>7.34154</td></tr><tr><td>train/learning_rate</td><td>0.00029</td></tr><tr><td>train/loss</td><td>1.2662</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">visionary-hill-27</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/mt7uf0o4' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/mt7uf0o4</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_060417-mt7uf0o4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_060644-rnojcwfv</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/rnojcwfv' target=\"_blank\">wise-serenity-28</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/rnojcwfv' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/rnojcwfv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 120/1350 02:49 < 29:29, 0.70 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>7.686800</td>\n",
              "      <td>2.961586</td>\n",
              "      <td>0.379167</td>\n",
              "      <td>0.269345</td>\n",
              "      <td>0.379167</td>\n",
              "      <td>0.292226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.034700</td>\n",
              "      <td>1.346217</td>\n",
              "      <td>0.564583</td>\n",
              "      <td>0.565044</td>\n",
              "      <td>0.564583</td>\n",
              "      <td>0.534624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.220500</td>\n",
              "      <td>1.071390</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.677125</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>0.610732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.102800</td>\n",
              "      <td>1.017126</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.672577</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.616217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.101400</td>\n",
              "      <td>0.943137</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.675797</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.651063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.990400</td>\n",
              "      <td>0.902163</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.659646</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.636908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:09:36,307] Trial 11 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68125</td></tr><tr><td>eval/f1</td><td>0.63691</td></tr><tr><td>eval/loss</td><td>0.90216</td></tr><tr><td>eval/precision</td><td>0.65965</td></tr><tr><td>eval/recall</td><td>0.68125</td></tr><tr><td>eval/runtime</td><td>5.1274</td></tr><tr><td>eval/samples_per_second</td><td>93.615</td></tr><tr><td>eval/steps_per_second</td><td>11.702</td></tr><tr><td>train/epoch</td><td>0.88889</td></tr><tr><td>train/global_step</td><td>120</td></tr><tr><td>train/grad_norm</td><td>12.25276</td></tr><tr><td>train/learning_rate</td><td>0.00014</td></tr><tr><td>train/loss</td><td>0.9904</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wise-serenity-28</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/rnojcwfv' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/rnojcwfv</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_060644-rnojcwfv/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_060939-tpz4ye1b</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/tpz4ye1b' target=\"_blank\">spring-paper-29</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/tpz4ye1b' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/tpz4ye1b</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 100/1350 02:21 < 29:59, 0.69 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>8.622500</td>\n",
              "      <td>5.540625</td>\n",
              "      <td>0.014583</td>\n",
              "      <td>0.197110</td>\n",
              "      <td>0.014583</td>\n",
              "      <td>0.009541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.004700</td>\n",
              "      <td>1.497167</td>\n",
              "      <td>0.552083</td>\n",
              "      <td>0.556917</td>\n",
              "      <td>0.552083</td>\n",
              "      <td>0.510821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.412000</td>\n",
              "      <td>1.073476</td>\n",
              "      <td>0.618750</td>\n",
              "      <td>0.555637</td>\n",
              "      <td>0.618750</td>\n",
              "      <td>0.545800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.151300</td>\n",
              "      <td>0.982192</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.642713</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.612997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.053700</td>\n",
              "      <td>0.916430</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.639511</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.639383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:12:02,697] Trial 12 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.70417</td></tr><tr><td>eval/f1</td><td>0.63938</td></tr><tr><td>eval/loss</td><td>0.91643</td></tr><tr><td>eval/precision</td><td>0.63951</td></tr><tr><td>eval/recall</td><td>0.70417</td></tr><tr><td>eval/runtime</td><td>5.1063</td></tr><tr><td>eval/samples_per_second</td><td>94.002</td></tr><tr><td>eval/steps_per_second</td><td>11.75</td></tr><tr><td>train/epoch</td><td>0.74074</td></tr><tr><td>train/global_step</td><td>100</td></tr><tr><td>train/grad_norm</td><td>8.19965</td></tr><tr><td>train/learning_rate</td><td>6e-05</td></tr><tr><td>train/loss</td><td>1.0537</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">spring-paper-29</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/tpz4ye1b' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/tpz4ye1b</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_060939-tpz4ye1b/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_061206-vj29u2o1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/vj29u2o1' target=\"_blank\">youthful-disco-30</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/vj29u2o1' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/vj29u2o1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 31:59, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.020100</td>\n",
              "      <td>1.814332</td>\n",
              "      <td>0.481250</td>\n",
              "      <td>0.457310</td>\n",
              "      <td>0.481250</td>\n",
              "      <td>0.421036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.437200</td>\n",
              "      <td>1.104019</td>\n",
              "      <td>0.660417</td>\n",
              "      <td>0.695859</td>\n",
              "      <td>0.660417</td>\n",
              "      <td>0.633464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.059800</td>\n",
              "      <td>0.899600</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.727722</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.654274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.952000</td>\n",
              "      <td>0.816383</td>\n",
              "      <td>0.697917</td>\n",
              "      <td>0.690987</td>\n",
              "      <td>0.697917</td>\n",
              "      <td>0.665147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.890800</td>\n",
              "      <td>0.733265</td>\n",
              "      <td>0.727083</td>\n",
              "      <td>0.640709</td>\n",
              "      <td>0.727083</td>\n",
              "      <td>0.662883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.847900</td>\n",
              "      <td>0.713595</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.788076</td>\n",
              "      <td>0.752083</td>\n",
              "      <td>0.734955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.742700</td>\n",
              "      <td>0.602866</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.771818</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.741526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.716300</td>\n",
              "      <td>0.702408</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.759929</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.737431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.807300</td>\n",
              "      <td>1.059254</td>\n",
              "      <td>0.654167</td>\n",
              "      <td>0.754677</td>\n",
              "      <td>0.654167</td>\n",
              "      <td>0.626821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.791000</td>\n",
              "      <td>0.698489</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.820338</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.762445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.651100</td>\n",
              "      <td>0.691624</td>\n",
              "      <td>0.758333</td>\n",
              "      <td>0.779460</td>\n",
              "      <td>0.758333</td>\n",
              "      <td>0.734291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.740800</td>\n",
              "      <td>0.623791</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.757902</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.746112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.570100</td>\n",
              "      <td>0.598890</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.760571</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.747633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>0.558815</td>\n",
              "      <td>0.772917</td>\n",
              "      <td>0.782944</td>\n",
              "      <td>0.772917</td>\n",
              "      <td>0.756394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.510900</td>\n",
              "      <td>0.553735</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.738910</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.751873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.446500</td>\n",
              "      <td>0.537354</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.818160</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.781290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.441300</td>\n",
              "      <td>0.627743</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.759877</td>\n",
              "      <td>0.779167</td>\n",
              "      <td>0.742434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.570400</td>\n",
              "      <td>0.629229</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.779921</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.766813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.578100</td>\n",
              "      <td>0.582020</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.843596</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.797253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.533600</td>\n",
              "      <td>0.646387</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.807853</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.780555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.440400</td>\n",
              "      <td>0.575805</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.793812</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.777088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.455300</td>\n",
              "      <td>0.575863</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.812565</td>\n",
              "      <td>0.808333</td>\n",
              "      <td>0.793912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.398200</td>\n",
              "      <td>0.582494</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.770212</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.766990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.387100</td>\n",
              "      <td>0.528990</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.842785</td>\n",
              "      <td>0.822917</td>\n",
              "      <td>0.812260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.316500</td>\n",
              "      <td>0.527643</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.805582</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.806377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.405900</td>\n",
              "      <td>0.619166</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.836879</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.769337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.424600</td>\n",
              "      <td>0.581068</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.774628</td>\n",
              "      <td>0.785417</td>\n",
              "      <td>0.769920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.309700</td>\n",
              "      <td>0.566541</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.786541</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.784710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.253200</td>\n",
              "      <td>0.570830</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.810930</td>\n",
              "      <td>0.814583</td>\n",
              "      <td>0.806994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.259400</td>\n",
              "      <td>0.592367</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.771075</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.773942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.259000</td>\n",
              "      <td>0.539320</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.815470</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.814826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.280300</td>\n",
              "      <td>0.597982</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.807292</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.793283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.276600</td>\n",
              "      <td>0.626874</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.808983</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.785298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.258500</td>\n",
              "      <td>0.637764</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.833274</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.799703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.166600</td>\n",
              "      <td>0.644893</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.803669</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.790375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.194700</td>\n",
              "      <td>0.632590</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.837872</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.827767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.171900</td>\n",
              "      <td>0.655012</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.808605</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.800692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.172800</td>\n",
              "      <td>0.671627</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.789393</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.790796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.171000</td>\n",
              "      <td>0.697175</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.791543</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.786626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.160600</td>\n",
              "      <td>0.697847</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.820542</td>\n",
              "      <td>0.797917</td>\n",
              "      <td>0.801525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.134100</td>\n",
              "      <td>0.701093</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.838781</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.819337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.083600</td>\n",
              "      <td>0.722777</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.830430</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.808584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.764542</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.800742</td>\n",
              "      <td>0.795833</td>\n",
              "      <td>0.793578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.075300</td>\n",
              "      <td>0.805236</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.784742</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.777754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.760292</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.811849</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.811878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.080700</td>\n",
              "      <td>0.812814</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.825395</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.809978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.072600</td>\n",
              "      <td>0.764238</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.820290</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.812297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.032200</td>\n",
              "      <td>0.806095</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.817339</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.806988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.021700</td>\n",
              "      <td>0.865696</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.822326</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.808181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.016600</td>\n",
              "      <td>0.860771</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.807371</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.013700</td>\n",
              "      <td>0.862312</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.809790</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.803183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.874065</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.811054</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.804143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>0.874917</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.809635</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.804322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.017100</td>\n",
              "      <td>0.883287</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.813044</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.803103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.889939</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.813178</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.805659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>0.901807</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.815560</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.806903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.916216</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.807467</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.801991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>0.917764</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.811374</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.804659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.917953</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.810157</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>0.804265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.916983</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.812128</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.806579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>0.924071</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.814345</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.807397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.929571</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.817418</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.811007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.817418</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.811007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.930997</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.817418</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.811007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.930971</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.817418</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.811007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.930813</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.817418</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.811007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.931007</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.817418</td>\n",
              "      <td>0.810417</td>\n",
              "      <td>0.811007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:44:09,390] Trial 13 finished with value: 3.249258113240349 and parameters: {'learning_rate': 3.6923533172321525e-05, 'weight_decay': 0.0003130319048797875, 'warmup_ratio': 0.0026074350219428485}. Best is trial 0 with value: 3.3080778600181313.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.81042</td></tr><tr><td>eval/f1</td><td>0.81101</td></tr><tr><td>eval/loss</td><td>0.93101</td></tr><tr><td>eval/precision</td><td>0.81742</td></tr><tr><td>eval/recall</td><td>0.81042</td></tr><tr><td>eval/runtime</td><td>5.1763</td></tr><tr><td>eval/samples_per_second</td><td>92.73</td></tr><tr><td>eval/steps_per_second</td><td>11.591</td></tr><tr><td>total_flos</td><td>1.1345892843139891e+19</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>1350</td></tr><tr><td>train/grad_norm</td><td>0.08251</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0014</td></tr><tr><td>train_loss</td><td>0.37696</td></tr><tr><td>train_runtime</td><td>1924.4229</td></tr><tr><td>train_samples_per_second</td><td>22.448</td></tr><tr><td>train_steps_per_second</td><td>0.702</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">youthful-disco-30</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/vj29u2o1' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/vj29u2o1</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_061206-vj29u2o1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_064411-dfqljfdo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/dfqljfdo' target=\"_blank\">summer-hill-31</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/dfqljfdo' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/dfqljfdo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  20/1350 00:27 < 33:31, 0.66 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.832400</td>\n",
              "      <td>9.478548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:44:41,661] Trial 14 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0</td></tr><tr><td>eval/f1</td><td>0</td></tr><tr><td>eval/loss</td><td>9.47855</td></tr><tr><td>eval/precision</td><td>0</td></tr><tr><td>eval/recall</td><td>0</td></tr><tr><td>eval/runtime</td><td>5.1345</td></tr><tr><td>eval/samples_per_second</td><td>93.485</td></tr><tr><td>eval/steps_per_second</td><td>11.686</td></tr><tr><td>train/epoch</td><td>0.14815</td></tr><tr><td>train/global_step</td><td>20</td></tr><tr><td>train/grad_norm</td><td>26.67921</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>9.8324</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">summer-hill-31</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/dfqljfdo' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/dfqljfdo</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_064411-dfqljfdo/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_064444-poa3xs6h</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/poa3xs6h' target=\"_blank\">resilient-field-32</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/poa3xs6h' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/poa3xs6h</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 120/1350 02:49 < 29:23, 0.70 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>6.196100</td>\n",
              "      <td>2.242702</td>\n",
              "      <td>0.387500</td>\n",
              "      <td>0.354248</td>\n",
              "      <td>0.387500</td>\n",
              "      <td>0.319003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.630800</td>\n",
              "      <td>1.185530</td>\n",
              "      <td>0.589583</td>\n",
              "      <td>0.624311</td>\n",
              "      <td>0.589583</td>\n",
              "      <td>0.553023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.186900</td>\n",
              "      <td>1.054994</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.585364</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.586651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.082000</td>\n",
              "      <td>0.982414</td>\n",
              "      <td>0.677083</td>\n",
              "      <td>0.702597</td>\n",
              "      <td>0.677083</td>\n",
              "      <td>0.642757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.067100</td>\n",
              "      <td>0.736641</td>\n",
              "      <td>0.714583</td>\n",
              "      <td>0.671619</td>\n",
              "      <td>0.714583</td>\n",
              "      <td>0.659017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.932200</td>\n",
              "      <td>0.896599</td>\n",
              "      <td>0.689583</td>\n",
              "      <td>0.713456</td>\n",
              "      <td>0.689583</td>\n",
              "      <td>0.658093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:47:35,836] Trial 15 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68958</td></tr><tr><td>eval/f1</td><td>0.65809</td></tr><tr><td>eval/loss</td><td>0.8966</td></tr><tr><td>eval/precision</td><td>0.71346</td></tr><tr><td>eval/recall</td><td>0.68958</td></tr><tr><td>eval/runtime</td><td>5.1048</td></tr><tr><td>eval/samples_per_second</td><td>94.028</td></tr><tr><td>eval/steps_per_second</td><td>11.754</td></tr><tr><td>train/epoch</td><td>0.88889</td></tr><tr><td>train/global_step</td><td>120</td></tr><tr><td>train/grad_norm</td><td>11.23283</td></tr><tr><td>train/learning_rate</td><td>0.00013</td></tr><tr><td>train/loss</td><td>0.9322</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resilient-field-32</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/poa3xs6h' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/poa3xs6h</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_064444-poa3xs6h/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_064739-8pq59ow2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/8pq59ow2' target=\"_blank\">eager-dream-33</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/8pq59ow2' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/8pq59ow2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  20/1350 00:27 < 33:35, 0.66 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.457800</td>\n",
              "      <td>8.160962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:48:09,176] Trial 16 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0</td></tr><tr><td>eval/f1</td><td>0</td></tr><tr><td>eval/loss</td><td>8.16096</td></tr><tr><td>eval/precision</td><td>0</td></tr><tr><td>eval/recall</td><td>0</td></tr><tr><td>eval/runtime</td><td>5.1152</td></tr><tr><td>eval/samples_per_second</td><td>93.838</td></tr><tr><td>eval/steps_per_second</td><td>11.73</td></tr><tr><td>train/epoch</td><td>0.14815</td></tr><tr><td>train/global_step</td><td>20</td></tr><tr><td>train/grad_norm</td><td>21.86611</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>9.4578</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">eager-dream-33</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/8pq59ow2' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/8pq59ow2</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_064739-8pq59ow2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_064812-7vjowtq3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/7vjowtq3' target=\"_blank\">azure-hill-34</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/7vjowtq3' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/7vjowtq3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 100/1350 02:21 < 30:00, 0.69 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>7.277000</td>\n",
              "      <td>2.639747</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.309238</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.221618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.916200</td>\n",
              "      <td>1.223843</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.566687</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.560647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.165000</td>\n",
              "      <td>1.072398</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.706743</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.612599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.166200</td>\n",
              "      <td>1.014973</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.697602</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.648189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.129100</td>\n",
              "      <td>0.841802</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.650965</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.617974</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:50:36,190] Trial 17 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.675</td></tr><tr><td>eval/f1</td><td>0.61797</td></tr><tr><td>eval/loss</td><td>0.8418</td></tr><tr><td>eval/precision</td><td>0.65096</td></tr><tr><td>eval/recall</td><td>0.675</td></tr><tr><td>eval/runtime</td><td>5.1533</td></tr><tr><td>eval/samples_per_second</td><td>93.145</td></tr><tr><td>eval/steps_per_second</td><td>11.643</td></tr><tr><td>train/epoch</td><td>0.74074</td></tr><tr><td>train/global_step</td><td>100</td></tr><tr><td>train/grad_norm</td><td>8.75791</td></tr><tr><td>train/learning_rate</td><td>0.00014</td></tr><tr><td>train/loss</td><td>1.1291</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">azure-hill-34</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/7vjowtq3' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/7vjowtq3</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_064812-7vjowtq3/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_065039-x783mbuc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/x783mbuc' target=\"_blank\">apricot-donkey-35</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/x783mbuc' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/x783mbuc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 100/1350 02:21 < 30:01, 0.69 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>6.601400</td>\n",
              "      <td>2.660876</td>\n",
              "      <td>0.322917</td>\n",
              "      <td>0.254914</td>\n",
              "      <td>0.322917</td>\n",
              "      <td>0.246183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.822300</td>\n",
              "      <td>1.152165</td>\n",
              "      <td>0.622917</td>\n",
              "      <td>0.584742</td>\n",
              "      <td>0.622917</td>\n",
              "      <td>0.564309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.165800</td>\n",
              "      <td>0.965761</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.670715</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.636365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.230200</td>\n",
              "      <td>0.957247</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.682915</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>0.633824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.159000</td>\n",
              "      <td>1.021179</td>\n",
              "      <td>0.689583</td>\n",
              "      <td>0.619166</td>\n",
              "      <td>0.689583</td>\n",
              "      <td>0.616362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:53:03,423] Trial 18 pruned. \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/grad_norm</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68958</td></tr><tr><td>eval/f1</td><td>0.61636</td></tr><tr><td>eval/loss</td><td>1.02118</td></tr><tr><td>eval/precision</td><td>0.61917</td></tr><tr><td>eval/recall</td><td>0.68958</td></tr><tr><td>eval/runtime</td><td>5.1522</td></tr><tr><td>eval/samples_per_second</td><td>93.163</td></tr><tr><td>eval/steps_per_second</td><td>11.645</td></tr><tr><td>train/epoch</td><td>0.74074</td></tr><tr><td>train/global_step</td><td>100</td></tr><tr><td>train/grad_norm</td><td>5.94915</td></tr><tr><td>train/learning_rate</td><td>0.00021</td></tr><tr><td>train/loss</td><td>1.159</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">apricot-donkey-35</strong> at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/x783mbuc' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/x783mbuc</a><br> View project at: <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250424_065039-x783mbuc/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_065306-utro6r0q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/utro6r0q' target=\"_blank\">light-deluge-36</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/utro6r0q' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/vit-hybrid-medmnist/runs/utro6r0q</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  20/1350 00:27 < 33:48, 0.66 it/s, Epoch 0/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>8.883000</td>\n",
              "      <td>6.358665</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.000718</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.001068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-24 06:53:36,386] Trial 19 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best run: BestRun(run_id='0', objective=3.3080778600181313, hyperparameters={'learning_rate': 8.935931938095857e-05, 'weight_decay': 0.04409991855514803, 'warmup_ratio': 0.03880873135635299}, run_summary=None)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import optuna\n",
        "\n",
        "import os\n",
        "\n",
        "# all runs go into this projec\n",
        "os.environ[\"WANDB_PROJECT\"]   = \"vit-hybrid-medmnist\"\n",
        "os.environ[\"WANDB_RUN_GROUP\"] = \"hpsearch2\"\n",
        "\n",
        "def model_init():\n",
        "    model =  ViTHybridForImageClassification.from_pretrained(\"google/vit-hybrid-base-bit-384\")\n",
        "    model.config.num_labels = num_labels\n",
        "    return model\n",
        "\n",
        "def hp_space(trial: optuna.Trial):\n",
        "    return {\n",
        "        # try LR between 5e6 and 5e5, log scale\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-6, 5e-4, log=True),\n",
        "        # weight decay\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
        "        # warmup ratio\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.0, 0.2),\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vit-hybrid-medmnist-hpsearch\",\n",
        "    num_train_epochs=10,\n",
        "    eval_strategy=\"steps\",\n",
        "    per_device_train_batch_size=32,\n",
        "    lr_scheduler_type= \"cosine_with_restarts\",\n",
        "    eval_steps=20,\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=True,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=20,\n",
        "    seed=42,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_accuracy\",\n",
        "    run_name=\"hpsearch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "best_run = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    n_trials=20,\n",
        "    hp_space=hp_space,\n",
        ")\n",
        "\n",
        "print(\"Best run:\", best_run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "l6H-AHBQhMtI",
        "outputId": "60d3a671-1984-4eb2-face-8acb1632c424"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmlabrie0208\u001b[0m (\u001b[33mmlabrie0208-polytechnique-montr-al\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250424_023739-ux4tcuve</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/huggingface/runs/ux4tcuve' target=\"_blank\">ln5-5,epoch5</a></strong> to <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/huggingface' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mlabrie0208-polytechnique-montr-al/huggingface/runs/ux4tcuve' target=\"_blank\">https://wandb.ai/mlabrie0208-polytechnique-montr-al/huggingface/runs/ux4tcuve</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [330/330 26:59, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>6.972000</td>\n",
              "      <td>2.239891</td>\n",
              "      <td>0.393750</td>\n",
              "      <td>0.373662</td>\n",
              "      <td>0.393750</td>\n",
              "      <td>0.307418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.488500</td>\n",
              "      <td>0.935833</td>\n",
              "      <td>0.691667</td>\n",
              "      <td>0.684936</td>\n",
              "      <td>0.691667</td>\n",
              "      <td>0.674322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.899000</td>\n",
              "      <td>0.782406</td>\n",
              "      <td>0.745833</td>\n",
              "      <td>0.725262</td>\n",
              "      <td>0.745833</td>\n",
              "      <td>0.725896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.694400</td>\n",
              "      <td>0.700448</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.729078</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.713400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.630800</td>\n",
              "      <td>0.678789</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.812334</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.794123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.556400</td>\n",
              "      <td>0.643094</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.796348</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.771337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.466200</td>\n",
              "      <td>0.663707</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.790408</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.762253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.407500</td>\n",
              "      <td>0.629783</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.814199</td>\n",
              "      <td>0.789583</td>\n",
              "      <td>0.789688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.364200</td>\n",
              "      <td>0.607080</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.770169</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.771781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.307600</td>\n",
              "      <td>0.619233</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.792909</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.779475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.261200</td>\n",
              "      <td>0.624031</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.804730</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.804024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.227500</td>\n",
              "      <td>0.645278</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.793933</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.790368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.166800</td>\n",
              "      <td>0.671661</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.812911</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.804177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.169300</td>\n",
              "      <td>0.667116</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800038</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.796832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.127600</td>\n",
              "      <td>0.685391</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.794487</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.791444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.128800</td>\n",
              "      <td>0.692826</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.796048</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.791841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Adjusted training arguments to use a smaller batch size and gradient accumulation.\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vit-hybrid-medmnist\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=128,\n",
        "    gradient_accumulation_steps=grad_accum,\n",
        "    num_train_epochs=10,\n",
        "\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=20,\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=True,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=20,\n",
        "    seed=42,\n",
        "\n",
        "    save_steps=steps_per_epoch,\n",
        "    learning_rate=2e-5,\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",\n",
        "    warmup_ratio= 0.05,\n",
        "    weight_decay=0.09,\n",
        "\n",
        "    report_to=[\"wandb\"],\n",
        "    run_name=\"ln5-5,epoch5\",\n",
        ")\n",
        "\n",
        "\n",
        "# Create a Trainer for fine-tuning our model.\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Start the fine-tuning process.\n",
        "train_results = trainer.train()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMeRmFOfoCOj",
        "outputId": "77870512-3d18-49f3-a48e-1cdddc958a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model saved at /content/drive/MyDrive/Project_Deep_Learning/finetuned_model2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_directory = \"/content/drive/MyDrive/Project_Deep_Learning/finetuned_model2\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "trainer.save_model(save_directory)\n",
        "print(f\"Model saved at {save_directory}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "pyXHPeX4TkdD",
        "outputId": "9f20d0ba-f56a-435d-bd84-a6deef2e2890"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='21' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:34]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuned metrics: {'eval_loss': 0.692058265209198, 'eval_accuracy': 0.79375, 'eval_precision': 0.7960479532135712, 'eval_recall': 0.79375, 'eval_f1': 0.7918406239775988, 'eval_runtime': 6.677, 'eval_samples_per_second': 71.889, 'eval_steps_per_second': 0.599, 'epoch': 9.71111111111111}\n",
            "***** train metrics *****\n",
            "  epoch                    =        9.7111\n",
            "  total_flos               = 10261426312GF\n",
            "  train_loss               =        0.8446\n",
            "  train_runtime            =    0:27:07.69\n",
            "  train_samples_per_second =        26.541\n",
            "  train_steps_per_second   =         0.203\n",
            "***** eval metrics *****\n",
            "  epoch                   =     9.7111\n",
            "  eval_accuracy           =     0.7937\n",
            "  eval_f1                 =     0.7918\n",
            "  eval_loss               =     0.6921\n",
            "  eval_precision          =      0.796\n",
            "  eval_recall             =     0.7937\n",
            "  eval_runtime            = 0:00:06.67\n",
            "  eval_samples_per_second =     71.899\n",
            "  eval_steps_per_second   =      0.599\n",
            "Test set metrics: {'eval_loss': 0.7182607054710388, 'eval_accuracy': 0.788125, 'eval_precision': 0.7821459550070182, 'eval_recall': 0.788125, 'eval_f1': 0.7829282889569362, 'eval_runtime': 22.1742, 'eval_samples_per_second': 72.156, 'eval_steps_per_second': 0.586, 'epoch': 9.71111111111111}\n"
          ]
        }
      ],
      "source": [
        "# After training, evaluate the fine-tuned model on the validation set.\n",
        "finetuned_metrics = trainer.evaluate()\n",
        "print(\"Fine-tuned metrics:\", finetuned_metrics)\n",
        "\n",
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_state()\n",
        "\n",
        "metrics = trainer.evaluate(val_dataset)\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)\n",
        "\n",
        "\n",
        "test_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Test set metrics:\", test_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLe-ro6CYjXp",
        "outputId": "aaa035b9-1b90-4fbf-9363-549163f85d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning Top-1 Accuracy on test dataset: 78.8125%\n",
            "Fine-tuning Top-5 Accuracy on test dataset: 99.25%\n"
          ]
        }
      ],
      "source": [
        "def TopKAccuracy(test_dataset, k):\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for idx in range(len(test_dataset)):\n",
        "    image = test_dataset[idx]['pixel_values'].to(model.device)\n",
        "    outputs = model(image.unsqueeze(0))\n",
        "    logits = outputs.logits\n",
        "\n",
        "    values, indices = torch.topk(logits, k)\n",
        "    indices = indices.tolist()\n",
        "\n",
        "    if test_dataset[idx]['labels'].item() in indices[0]:\n",
        "      correct_predictions += 1\n",
        "\n",
        "  print(f\"Fine-tuning Top-{k} Accuracy on test dataset: {(correct_predictions / len(test_dataset))*100}%\")\n",
        "\n",
        "\n",
        "TopKAccuracy(test_dataset, 1)\n",
        "TopKAccuracy(test_dataset, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TzaoUhm35LQZ"
      },
      "outputs": [],
      "source": [
        "def predict(idx):\n",
        "  image = test_dataset[idx]['pixel_values'].to(model.device)\n",
        "\n",
        "  outputs = model(image.unsqueeze(0))\n",
        "  logits = outputs.logits\n",
        "\n",
        "  predicted_class_idx = logits.argmax(-1).item()\n",
        "  real_class_idx = test_dataset[idx]['labels'].item()\n",
        "  print(\"Predicted class:\", model.config.id2label[f'{predicted_class_idx}'])\n",
        "  print(\"Real Class: \", model.config.id2label[f'{real_class_idx}'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "7dxn8WQNhEmQ",
        "outputId": "2208262b-88e7-479a-daf7-e1a48d0853e0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = trainer.state.log_history\n",
        "df = pd.DataFrame(logs)\n",
        "\n",
        "train_loss = df[df['loss'].notna()][['step','loss']]\n",
        "\n",
        "eval_metrics = df[df['eval_loss'].notna()][['step','eval_loss','eval_accuracy']]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_loss['step'], train_loss['loss'], label='Train Loss')\n",
        "plt.plot(eval_metrics['step'], eval_metrics['eval_loss'], label='Val Loss')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(eval_metrics['step'], eval_metrics['eval_accuracy'], label='Val Accuracy')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
